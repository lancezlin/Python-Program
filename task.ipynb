{
 "metadata": {
  "name": "",
  "signature": "sha256:cd38a86fabdea9d408deec6d0d6d954faf8628624ae110ded151cb53cecab902"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Loading modules**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import linear_model\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn import metrics\n",
      "%cd \"~/Downloads\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/lance/Downloads\n"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Manipulating dataset to the format that fit the model**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv = pd.read_csv('prediction_exercise_train.csv', sep=',', header=False)\n",
      "conv = conv.groupby(['entity_id', 'device']).mean()\n",
      "conv.loc[conv[\"Conversions\"]>0, \"Target\"] = 1\n",
      "conv.loc[conv[\"Conversions\"]==0, \"Target\"] = 0\n",
      "conv = conv.drop(['week', 'Conversions'], 1)\n",
      "conv.to_csv(\"conv.csv\")\n",
      "conv1 = pd.read_csv('conv.csv', sep=',', header=False)\n",
      "dummy_device = pd.get_dummies(conv1['device'], prefix='Device')\n",
      "conv2 = conv1.join(dummy_device.ix[:, 'Device_Smartphone':])\n",
      "ids = conv2.ix[:, :2]\n",
      "data = conv2.ix[:, 2 : ].drop('Target', 1)\n",
      "target = conv2.ix[:, -1:]\n",
      "X, y = pd.DataFrame.as_matrix(data), pd.DataFrame.as_matrix(target)\n",
      "y = np.ravel(y)\n",
      "shape(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "(37247, 163)"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Split the dataset into training and testing portions**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "**Reducing variables to keep only important ones and fit logistic model**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
      "model = linear_model.LogisticRegression()\n",
      "model.fit_transform(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "array([[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
        "       [ 1.,  0.,  1., ...,  1.,  0.,  0.],\n",
        "       ..., \n",
        "       [ 1.,  0.,  0., ...,  1.,  0.,  0.],\n",
        "       [ 1.,  0.,  1., ...,  1.,  1.,  0.],\n",
        "       [ 1.,  1.,  1., ...,  1.,  1.,  0.]])"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = model.predict(X_test)\n",
      "probs = model.predict_proba(X_test)\n",
      "probs2 = model.predict_proba(X_train)\n",
      "ids.join(probs_df)\n",
      "probs3 = np.concatenate((probs2, probs), axis=0)\n",
      "probs_df = pd.DataFrame(probs3, columns=['prediction', 'no'])\n",
      "#ids.join(probs_df)\n",
      "print X_train\n",
      "print probs2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0.    0.    1.  ...,   2.5   0.    0. ]\n",
        " [  0.    0.    0.  ...,   1.    0.    0. ]\n",
        " [  1.    0.    1.  ...,   7.    0.    0. ]\n",
        " ..., \n",
        " [  1.    0.    0.  ...,   1.    0.    0. ]\n",
        " [  1.    0.    1.  ...,  27.    1.    0. ]\n",
        " [  1.    1.    1.  ...,   3.    1.    0. ]]\n",
        "[[  9.98879583e-01   1.12041685e-03]\n",
        " [  9.99317583e-01   6.82417175e-04]\n",
        " [  9.98609183e-01   1.39081664e-03]\n",
        " ..., \n",
        " [  9.98797427e-01   1.20257256e-03]\n",
        " [  9.99842997e-01   1.57003177e-04]\n",
        " [  9.99891097e-01   1.08902970e-04]]\n"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**generating the class probabilities**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Generating the evaluation metrics, also see the confusion matrix and classification report**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.accuracy_score(y_test, pred)\n",
      "print metrics.roc_auc_score(y_test, probs[:, 1])\n",
      "print metrics.confusion_matrix(y_test, pred)\n",
      "print metrics.classification_report(y_test, pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "1.0\n",
        "[[8453    0]\n",
        " [   0 2722]]\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       1.00      1.00      1.00      8453\n",
        "        1.0       1.00      1.00      1.00      2722\n",
        "\n",
        "avg / total       1.00      1.00      1.00     11175\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Model evaluation using Cross-Validation**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lg = linear_model.LogisticRegression()\n",
      "scores = cross_val_score(lg, X, y, scoring='accuracy', cv=10)\n",
      "print scores\n",
      "print scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 163
    }
   ],
   "metadata": {}
  }
 ]
}